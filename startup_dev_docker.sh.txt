# steps to start from dev_docker image

cd ~git_repo/dev_docker/
# make build
make scale_count=3

# rename containers
docker container rename dev_docker_dev_1 dev_kafka_server_1
docker container rename dev_docker_dev_2 dev_kafka_consumer_1
docker container rename dev_docker_dev_3 dev_kafka_producer_1

# start containers
docker container start dev_kafka_producer_1 dev_kafka_consumer_1 dev_kafka_server_1
docker ps

# copy kafka binaries/jars into containers
tar -xf ~/Downloads/kafka_2.11-1.1.0.tar -C ~/Downloads
docker cp ~/Downloads/kafka_2.11-1.1.0 dev_kafka_producer_1:/opt
docker cp ~/Downloads/kafka_2.11-1.1.0 dev_kafka_consumer_1:/opt
docker cp ~/Downloads/kafka_2.11-1.1.0 dev_kafka_server_1:/opt


# dev_kafka_server_1
# start kafka server
docker attach dev_kafka_server_1
cd /opt/kafka_2.11-1.1.0/
bin/zookeeper-server-start.sh -daemon config/zookeeper.properties
bin/kafka-server-start.sh -daemon config/server.properties
#create topic 
bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic spark_kafka_events


# produce
docker attach dev_kafka_producer_1
cd /opt/git_repo/kafka_try
make -f producer.makefile


# consumer
docker attach dev_kafka_consumer_1
cd /opt/git_repo/kafka_try
make -f consumer.makefile